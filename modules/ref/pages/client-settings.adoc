= Client Settings for the Java SDK
:nav-title: Client Settings
:page-topic-type: reference
:page-aliases: ROOT:client-settings, ROOT:env-config

[abstract]
The `ClusterEnvironment` class enables you to configure Java SDK options for bootstrapping, timeouts, reliability, and performance.

include::ref:partial$beta-warning.adoc[]

WARNING: This page is being built -- it is not linked from the navigation -- much of it is still to be updated, and/or is just plain _wrong_.
Do not use!


== The Environment Builder

Most client settings are related to the `ClusterEnvironment`.
Because `ClusterEnvironment` is an immutable class, you need to configure it by using its embedded `Builder` class.
It is designed to apply the builder arguments in a fluent fashion and then create the `ClusterEnvironment` at the very end.

.Creating a cluster with custom settings
[source,java]
----
ClusterEnvironment env = ClusterEnvironment.builder()
    // [Customize client settings here]
    .build();

// Create a cluster using the custom client settings.
Cluster cluster = Cluster.connect(connectionString, ClusterOptions
    .clusterOptions(username, password)
    .environment(environment));

// [Your code to interact with the cluster]

// Shut down gracefully.
cluster.disconnect();
env.shutdown();
----

== Config Builders

Environment settings are grouped into categories, with one builder class per category.
These builders all work in the same way, which we'll illustrate by using timeout settings as an example.

Timeout settings are configured using an instance of `TimeoutConfig.Builder`.
The usual way to create an instance is to call a static factory method on the `TimeoutConfig` class.
The method `TimeoutConfig.builder()` returns a builder with default settings.
There are also static factory methods that create a builder and set a configuration value in one step.
For example, instead of `TimeoutConfig.builder().kvTimeout(...)` you can write simply `TimeoutConfig.kvTimeout(...)`.

.Creating a new timeout config builder
[source,java]
----
ClusterEnvironment env = ClusterEnvironment.builder()
    .timeoutConfig(TimeoutConfig
        .kvTimeout(Duration.ofSeconds(5))
        .queryTimeout(Duration.ofSeconds(10)))
    .build();
----

Another way to obtain an instance of a config builder is to borrow it from the cluster environment builder.
This technique may be useful if you're configuring the environment in stages and wish to preserve values set by a previous stage.

.Borrowing the existing timeout config builder
[source,java]
----
ClusterEnvironment.Builder envBuilder = ClusterEnvironment.builder();
envBuilder.timeoutConfig() // returns a TimeoutConfig.Builder
    .kvTimeout(Duration.ofSeconds(5))
    .queryTimeout(Duration.ofSeconds(10));
ClusterEnvironment env = envBuilder.build();
----

The name of the cluster environment builder method for getting and setting each config builder always matches the name of the config class.
For example, `TimeoutConfig` is set via the environment builder's `timeoutConfig` method, `IoConfig` is set via the `ioConfig` method, and so on.

== System properties

Many client settings may also be configured by setting a Java system property.
If a system property is set, it always takes precedence over the builder setting.

[#duration-values]
.Configuration via system property
[source,java]
----
System.setProperty("com.couchbase.env.timeout.kvTimeout", "10s"); // <1>
System.setProperty("com.couchbase.env.timeout.queryTimeout", "15s");

ClusterEnvironment environment = ClusterEnvironment.builder()
    .timeoutConfig(TimeoutConfig.kvTimeout(Duration.ofSeconds(5))) // <2>
    .build();
----
<1> When specifying durations, `s` stands for seconds.
Other valid qualifiers are `ns` for nanoseconds, `us` for microseconds, `ms` for milliseconds, and `m` for minutes.
<2> The `kvTimeout` value specified via `TimeoutConfig.Builder` is overridden by the system property.
In this example the actual `kvTimeout` is 10 seconds, and the `queryTimeout` is 15 seconds.

TIP: System property names starting with `com.couchbase.env` are paths in a Java object graph rooted at the environment builder.
Setting the property `com.couchbase.env.timeout.kvTimeout` tells the SDK to invoke `envBuilder.timeoutConfig().kvTimeout(...)` using reflection.

== Configuration Options

The following tables cover all possible configuration options and explain their usage and default values.
The tables categorize the options into groups for bootstrapping, timeout, reliability, performance, and advanced options.

== Security Options

By default the client will connect to Couchbase Server using an unencrypted connection.
If you are using the Enterprise Edition, it's possible to secure the connection using TLS.

.Template for configuring security settings
[source,java]
----
ClusterEnvironment env = ClusterEnvironment.builder()
    .securityConfig(SecurityConfig
        .enableTls(true)
        ...)
    .build()
----

NOTE: Unless you set `enableTls` to `true`, none of the other security settings in this section have any effect.

Name: *Enabling Secure Connections*::
Builder Method: `SecurityConfig.enableTls(boolean)`
+
Default:  `false`
+
System Property: `com.couchbase.env.security.enableTls`
+
Set this to `true` to encrypt all communication between the client and server using TLS.
This feature requires the Enterprise Edition of Couchbase Server 3.0 or later.
If TLS is enabled you must also specify the trusted certificates by calling exactly one of `trustCertificate`, `trustCertificates`, or `trustManagerFactory`.
Please see the xref:howtos:managing-connections.adoc[Managing Connections] section for more details on how to set it up properly.

Name: *Disabling Native TLS Provider*::
Builder Method: `SecurityConfig.enableNativeTls(boolean)`
+
Default:  `true`
+
System Property: `com.couchbase.env.security.enableNativeTls`
+
When TLS is enabled, the client will by default use an optimized native TLS provider if one is available.
If for some reason you need to disable the native provider and use the JDK's portable provider instead, set this to `false`.
If `enableTls` is  `false` then `enableNativeTls` has no effect.

Name: *TLS Certificate Location*::
Builder Method: `SecurityConfig.trustCertificate(Path)`
+
Default:  N/A
+
System Property: `com.couchbase.env.security.trustCertificate`
+
Path to a file containing a single X.509 certificate to trust as a Certificate Authority when establishing secure connections.
See the xref:howtos:managing-connections.adoc#ssl[Connection Management] section for more details on how to set it up properly.

Name: *TLS Certificates*::
Builder Method: `SecurityConfig.trustCertificates(List<X509Certificate>)`
+
Default:  N/A
+
System Property: N/A
+
If you wish to trust more than one certificate, or prefer to load the certificate yourself, then call this method to specify the certificates to trust as Certificate Authorities when establishing secure connections.
See the xref:howtos:managing-connections.adoc#ssl[Connection Management] section for more details on how to set it up properly.

Name: *Custom TLS Trust Manager Factory*::
Builder Method: `SecurityConfig.trustManagerFactory(TrustManagerFactory)`
+
Default:  N/A
+
System Property: N/A
+
As an alternative to specifying the certificates to trust, you can specify a custom `TrustManagerFactory` to use when establishing secure connections.
See the xref:howtos:managing-connections.adoc#ssl[Connection Management] section for more details on how to set it up properly.


== I/O Options

I/O settings are represented by the Java class `IoConfig`.
The associated `ClusterEnvironement.Builder` method is called `ioConfig`.

.Template for configuring I/O settings
[source,java]
----
ClusterEnvironment env = ClusterEnvironment.builder()
    .ioConfig(IoConfig
        .networkResolution(NetworkResolution.AUTO)
        ...)
    .build()
----

Name: *DNS SRV Enabled*::
Builder Method: `IoConfig.enableDnsSrv(boolean)`
+
Default:  `false`
+
System Property: `com.couchbase.env.io.enableDnsSrv`
+
Set this to `true` if you want to get the bootstrap node list from a DNS SRV record.
See the xref:howtos:managing-connections.adoc#using-dns-srv-records[Connection Management] section for more information on how to use it properly.

Name: *Mutation Tokens Enabled*::
Builder Method: `IoConfig.mutationTokensEnabled(boolean)`
+
Default:  `true`
+
System Property: `com.couchbase.env.io.mutationTokensEnabled`
+
Mutation tokens allow enhanced durability requirements as well as advanced N1QL querying capabilities.
Set this to `false` if you do not require these features and wish to avoid the associated overhead.

Name: *Network Resolution*::
Builder Method: `IoConfig.networkResolution(NetworkResolution)`
+
Default:  `auto`
+
System Property: `com.couchbase.env.io.networkResolution`
+
NOTE: The system property value should be one of `auto`, `default`, or `external` (lower case).
+
Each node in the Couchbase Server cluster might have multiple addresses associated with it.
For example, a node might have one address that should be used when connecting from inside the same virtual network environment where the server is running, and a second address for connecting from outside the server's network environment.
+
By default the client will use a simple matching heuristic to determine which set of addresses to use (it will select the set of addresses that contains a seed node's host and port).
+
If you wish to override the heuristic, you can set this value to `default` if the client is running in the same network as the server, or `external` if the client is running in a different network.

Name: *Capture Traffic*::
Builder Method: `IoConfig.captureTraffic(ServiceType...)`
+
Default:  capture is disabled
+
System Property: `com.couchbase.env.io.captureTraffic`
+
TIP: Multiple services may be specified in the system property value using a comma-delimited list such as `KV,QUERY`.
To enable capture for all services, set the value of the system property to an empty string.
+
Call this method to log all traffic to the specified services.
If no services are specified, traffic to all services is captured.

Name: *Socket Keepalive*::
Builder Method: `IoConfig.enableTcpKeepAlives(boolean)`
+
Default:  `true`
+
System Property: `com.couchbase.env.io.enableTcpKeepAlives`
+
If enabled, the client periodically sends a TCP keepalive to the server to prevent firewalls and other network equipment from dropping idle TCP connections.

Name: *Socket Keepalive Interval*::
Builder Method: `IoConfig.tcpKeepAliveTime(Duration)`
+
Default:  `60s`
+
System Property: `com.couchbase.env.io.tcpKeepAliveTime`
+
The idle time after which a TCP keepalive gets fired.
(This setting has no effect if `enableTcpKeepAlives` is `false`.)
+
NOTE: This setting only propagates to the OS on Linux when the epoll transport is used.
On all other platforms, the OS-configured time is used (and you need to tune it there if you want to override the default interval).

Name: *Key/Value Endpoints per Node*::
Builder Method: `IoConfig.numKvConnections(int)`
+
Default:  `1`
+
System Property: `com.couchbase.env.io.numKvConnections`
+
The number of actual endpoints (sockets) to open per node in the cluster against the Key/Value service.
By default, for every node in the cluster one socket is opened where all traffic is pushed through.
That way the SDK implicitly benefits from network batching characteristics when the workload increases.
If you suspect based on profiling and benchmarking that the socket is saturated you can think about slightly increasing it to have more "parallel pipelines".
This might be especially helpful if you need to push large documents through it.
The recommendation is keeping it at 1 unless there is other evidence.
+
NOTE: xref:concept-docs:durability-replication-failure-considerations.adoc#synchronous-writes[Durable Write] operations with Couchbase Server 6.5 and above require up to 16 KV Endpoints per node, for most efficient operation, unless the environment dictates something a little lower.

Name: *Max HTTP Endpoints per Service per Node*::
Builder Method: `IoConfig.maxHttpConnections(int)`
+
Default:  `12`
+
System Property: `com.couchbase.env.io.maxHttpConnections`
+
Each service (except the Key/Value service) has a separate dynamically sized pool of HTTP connections for issuing requests.
This setting puts an upper bound on the number of HTTP connections in each pool.

Name: *Idle HTTP Connection Timeout*::
Builder Method: `IoConfig.idleHttpConnectionTimeout(Duration)`
+
Default:  `5m`
+
System Property: `com.couchbase.env.io.idleHttpConnectionTimeout`
+
The length of time an HTTP connection may remain idle before it is closed and removed from the pool.


=== Circuit Breaker Options

Circuit breakers are a tool for preventing cascading failures.

When a circuit is closed, requests are sent to the server as normal.
If too many requests fail within a certain time window, the breaker opens the circuit, preventing requests from going through.

When a circuit is open, any requests to the service immediately fail without the client even talking to the server.
After a "sleep delay" elapses, the next request is allowed to go through the to the server. This trial request is called a "canary."

Each service has an associated circuit breaker which may be configured independently of the others.
The `IoConfig` builder has methods for configuring the circuit breakers of each service.

.Template for configuring circuit breaker settings
[source,java]
----
ClusterEnvironment env = ClusterEnvironment.builder()
    .ioConfig(IoConfig.
        kvCircuitBreakerConfig(CircuitBreakerConfig.builder()
            .enabled(true)
            .volumeThreshold(45)
            .errorThresholdPercentage(25)
            .sleepWindow(Duration.ofSeconds(1))
            .rollingWindow(Duration.ofMinutes(2))
        ))
    .build();
----

The corresponding system properties would be:

[source,properties]
----
com.couchbase.env.io.kvCircuitBreaker.enabled=true
com.couchbase.env.io.kvCircuitBreaker.volumeThreshold=45
com.couchbase.env.io.kvCircuitBreaker.errorThresholdPercentage=25
com.couchbase.env.io.kvCircuitBreaker.sleepWindow=1s
com.couchbase.env.io.kvCircuitBreaker.rollingWindow=2m
----

For the other services, replace `kv` with `query`, `view`, `search`, `analytics`, or `manager`.

The properties of a circuit breaker are described below.

enabled::
Default: `true`
+
Enables or disables this circuit breaker.
+
If this property is set to false, then the circuit breaker is not used and all other properties are ignored.

volumeThreshold::
Default: `20`
+
The volume threshold defines how many operations must be in the window before the threshold percentage can be meaningfully calculated.

errorThresholdPercentage::
Default: `50`
+
The percentage of operations in a window that may fail before the circuit is opened.
The value is an integer in the range [1,100].

sleepWindow::
Default: `5s`
+
The delay between when the circuit opens and when the canary is tried.


rollingWindow::
Default: `1m`
+
How long the window is in which the number of failed ops are tracked in a rolling fashion.

== Timeout Options

The default timeout values are suitable for most environments, and should be adjusted only after profiling the expected latencies in your deployment environment.
If you get a timeout exception, it may be a symptom of another issue; increasing the timeout duration is sometimes not the best long-term solution.

Most timeouts can be overridden on a per-operation basis (for example, by passing a custom options block to a "get" or "query" method).
The values set here are used as the defaults when no per-operation timeout is specified.
See <<duration-values, setting duration values>> under xref:#system-properties[System Properties].

Timeout settings are represented by the Java class `TimeoutConfig`.
The associated `ClusterEnvironement.Builder` method is called `timeoutConfig`.

.Template for configuring timeouts
[source,java]
----
ClusterEnvironment env = ClusterEnvironment.builder()
    .timeoutConfig(TimeoutConfig
        .kvTimeout(Duration.ofMillis(2500))
        ...)
    .build()
----

=== Timeout Options Reference

Name: *Key-Value Timeout*::
Builder Method: `TimeoutConfig.kvTimeout(Duration)`
+
Default: `2.5s` -- _but see WARNING, below_
+
System Property: `com.couchbase.env.timeout.kvTimeout`
+
The Key/Value default timeout is used on operations which are performed on a specific key if not overridden by a custom timeout.
This includes all commands like get(), getFromReplica() and all mutation commands, but does not include operations that are performed with enhanced durability requirements.
+
WARNING: xref:concept-docs:durability-replication-failure-considerations.adoc#synchronous-writes[Durable Write operations] cause the default `kvTimeout` to be changed to 10s.
This may still be overridden by setting the above property.

Name: *Key-Value Durable Operation Timeout*::
Builder Method: `TimeoutConfig.kvDurableTimeout(Duration)`
+
Default: `10s`
+
System Property: `com.couchbase.env.timeout.kvDurableTimeout`
+
Key/Value operations with enhanced durability requirements may take longer to complete, so they have a separate default timeout.
+
WARNING: The `kvDurableTimeout` property is not part of the stable API and may change or be removed at any time.

Name: *View Timeout*::
Builder Method: `TimeoutConfig.viewTimeout(Duration)`
+
Default: `75s`
+
System Property: `com.couchbase.env.timeout.viewTimeout`
+
The View timeout is used on view operations if not overridden by a custom timeout.
Note that it is set to such a high timeout compared to key/value since it can affect hundreds or thousands of rows.
Also, if there is a node failure during the request the internal cluster timeout is set to 60 seconds.

Name: *Query Timeout*::
Builder Method: `TimeoutConfig.queryTimeout(Duration)`
+
Default: `75s`
+
System Property: `com.couchbase.env.timeout.queryTimeout`
+
The Query timeout is used on all N1QL query operations if not overridden by a custom timeout.
Note that it is set to such a high timeout compared to key/value since it can affect hundreds or thousands of rows.

Name: *Search Timeout*::
Builder Method: `TimeoutConfig.searchTimeout(Duration)`
+
Default: `75s`
+
System Property: `com.couchbase.env.timeout.searchTimeout`
+
The Search timeout is used on all FTS operations if not overridden by a custom timeout.
Note that it is set to such a high timeout compared to key/value since it can affect hundreds or thousands of rows.

Name: *Analytics Timeout*::
Builder Method: `TimeoutConfig.analyticsTimeout(Duration)`
+
Default: `75s`
+
System Property: `com.couchbase.env.timeout.analyticsTimeout`
+
The Analytics timeout is used on all Analytics query operations if not overridden by a custom timeout.
Note that it is set to such a high timeout compared to key/value since it can affect hundreds or thousands of rows.

Name: *Connect Timeout*::
Builder Method: `TimeoutConfig.connectTimeout(Duration)`
+
Default: `10s`
+
System Property: `com.couchbase.env.timeout.connectTimeout`
+
The connect timeout is used when a Bucket is opened and if not overridden by a custom timeout.
If you feel the urge to change this value to something higher, there is a good chance that your network is not properly set up.
Connecting to the server should in practice not take longer than a second on a reasonably fast network.

Name: *Disconnect Timeout*::
Builder Method: `TimeoutConfig.disconnectTimeout(Duration)`
+
Default: `10s`
+
System Property: `com.couchbase.env.timeout.disconnectTimeout`
+
The disconnect timeout is used when a Cluster is disconnected and if not overridden by a custom timeout.
A timeout is applied here always to make sure that your code does not get stuck at shutdown.
The default should provide enough time to drain all outstanding operations properly, but make sure to adapt this timeout to fit your application requirements.

Name: *Management Timeout*::
Builder Method: `TimeoutConfig.managementTimeout(Duration)`
+
Default: `75s`
+
System Property: `com.couchbase.env.timeout.managementTimeout`
+
The management timeout is used on all cluster management APIs (BucketManager, UserManager, CollectionManager, QueryIndexManager, etc.) if not overridden by a custom timeout.
The default is quite high because some operations (such as flushing a bucket, for example) might take a long time.


// Need to add 2500ms default durability timeout.
// & its behaviour
// does not stop the sync write?
// An ambiguous state?


== Reliability Options

Name: *Reconnect Delay*::
Builder Method: `reconnectDelay(Delay)`
+
Default:  `Exponential between 32ms and 4096ms`
+
System Property: `-`
+
The reconnect delay defines the time intervals between a socket getting closed on the SDK side and trying to reopen (reconnect) to it.
The default is to retry relatively quickly (32ms) and then gradually approach 4 second intervals, so that in case a server is longer down than usual the clients do not flood the server with socket requests.
Feel free to tune this interval based on your application requirements.
Applying a very large ceiling may lead to longer down times than needed, while very short delays may flood the target node and spam the network unnecessarily.

Name: *Retry Delay*::
Builder Method: `retryDelay(Delay)`
+
Default:  `Exponential between 100µs and 100ms`
+
System Property: `-`
+
When a request needs to be retried for some reason (for example if the retry strategy is best effort and the target node is not reachable), this delay configures the boundaries.
An internal counter tracks the number of retries for a given request and it gradually increases by default from a very quick 100 microseconds up to a 100 millisecond delay.
The operation will be retried until it succeeds or the maximum request lifetime is reached.
If you find yourself wanting to tweak this value to a very low setting, you might want to consider a different retry strategy like "fail fast" to get tighter control on the retry handling yourself.

Name: *Retry Strategy*::
Builder Method: `retryStrategy(RetryStrategy)`
+
Default:  `Best Effort`
+
System Property: `-`
+
The retry strategy decides if an operation should be retried or canceled.
While implementing a custom strategy is fairly advanced, the SDK ships with two out of the box: BestEffortRetryStrategy and FailFastRetryStrategy.
The first one will retry the operation until it either succeeds or the maximum request lifetime is reached.
The fail fast strategy will cancel it right away and therefore the client needs to be prepared to retry on its own, but gets much tighter control on when and how to retry.
See the advanced section in the documentation on more specific information on retry strategies and failure management.

Name: *Maximum Request Lifetime*::
Builder Method: `maxRequestLifetime(long)`
+
Default:  `75000ms`
+
System Property: `maxRequestLifetime`
+
The maximum request lifetime is used by the best effort retry strategy to decide if its time to cancel the request instead of retrying it again.
This is needed in order to prevent requests from circling around forever and occupying precious slots in the request ring buffer.
Make sure to set this higher than the largest timeout in your application, otherwise you risk requests being canceled prematurely.
This is why the default value is set to 75 seconds, which is the highest default timeout on the environment.


Name: *Config Poll Interval*::
Builder Method: `configPollInterval(long)`
+
Default:  `2500ms`
+
System Property: `configPollInterval`
+
This interval helps to tune the timeframe when the SDK proactively grabs a new configuration from the server to detect cluster changes in a timely fashion.



== Performance Options

Name: *Observe Interval*::
Builder Method: `observeIntervalDelay(Delay)`
+
Default:  `Exponential between 10µs and 100ms`
+
System Property: `-`
+
The way PersistTo and ReplicateTo work is that once the regular mutation operation succeeds, the key state on the target nodes is polled until the desired state is reached.
Since replication and persistence latency differs greatly on servers (fast or slow networks and disks), this value can be tuned for maximum efficiency.
The tradeoffs to consider here is how quickly the desired state is detected as well as how much the SDK will spam the network.
The default is an exponential delay, starting with very short intervals but very quickly approaching the 100 milliseconds if replication or persistence takes longer than expected.
You should monitor the average persistence and replication latency and adjust the delay accordingly.

Name: *View Endpoints per Node [Static]*::
Builder Method: `viewEndpoints(int)`
+
Default:  `The default is dynamic mode, please see next entry.`
+
System Property: `viewEndpoints`
+
The number of actual endpoints (sockets) to open per node in the cluster against the view service.
If you plan to run a view heavy workload, especially paired with larger responses, increasing this value significantly (most likely between 5 and 10) can provide greater throughput.
We recommend that you tune this value based on evidence obtained during benchmarking with a real workload.

Name: *View Endpoints per Node [Dynamic]*::
Builder Method: `viewServiceConfig(int, int, int)`
+
Default:  `(0, 12, 300)`
+
System Property: `viewServiceConfig`
+
To allow dynamic pooling, as an alternative to the fixed values of viewEndPoints. Need to set minimum and maximum number of Endpoints; whether or not the service is pipelined (more than one request at the same time on the same socket); and the minimum idle time, in seconds, after which the socket will be closed.
Note that if both viewEndpoints and viewServiceConfig are set, viewEndpoints takes priority.
This helps to ensure backwards compatibility.

Name: *Query Endpoints per Node [Static]*::
Builder Method: `queryEndpoints(int)`
+
Default:  `The default is dynamic mode, please see next entry.`
+
System Property: `queryEndpoints`
+
The number of actual endpoints (sockets) to open per node in the cluster against the query service.
If you plan to run a view heavy workload, especially paired with larger responses, increasing this value significantly (most likely between 5 and 10) can provide greater throughput.
We recommend that you tune this value based on evidence obtained during benchmarking with a real workload.

Name: *Query Endpoints per Node [Dynamic]*::
Builder Method: `queryServiceConfig(int, int, int)` or `queryServiceConfig(int, int)`
+
Default:  `(0, 12, 300)`
+
System Property: `queryServiceConfig`
+
To allow dynamic pooling, as an alternative to the fixed values of queryEndPoints. Need to set minimum and maximum number of Endpoints; whether or not the service is pipelined (more than one request at the same time on the same socket); and the minimum idle time, in seconds, after which the socket will be closed.
Note that if both queryEndpoints and queryServiceConfig are set, queryEndpoints takes priority.
This helps to ensure backwards compatibility.

Name: *Search Endpoints per Node [Static]*::
Builder Method: `searchEndpoints(int)`
+
Default:  `The default is dynamic mode, please see next entry.`
+
System Property: `searchEndpoints`
+
The number of actual endpoints (sockets) to open per Node in the cluster against the Search (FTS) service.
If you plan to run a query heavy workload, especially paired with larger responses, increasing this value significantly (most likely between 5 and 10) can provide greater throughput.
We recommend that you tune this value based on evidence obtained during benchmarking with a real workload.


Name: *Search Endpoints per Node [Dynamic]*::
`searchServiceConfig(int, int, int)` or `searchServiceConfig(int, int)`
+
Default:  `(0, 12, 300)`
+
System Property: `searchServiceConfig`
+
To allow dynamic pooling, as an alternative to the fixed values of searchEndPoints. Need to set minimum and maximum number of Endpoints; whether or not the service is pipelined (more than one request at the same time on the same socket); and the minimum idle time, in seconds, after which the socket will be closed.
Note that if both searchEndpoints and searchServiceConfig are set, queryEndpoints takes priority.
This helps to ensure backwards compatibility.

Name: *I/O Thread Pool Size*::
Builder Method: `ioPoolSize(int)`
+
Default:  `Runtime#availableProcessors()`
+
System Property: `ioPoolSize`
+
The number of threads in the I/O thread pool.
This defaults to the number of available processors that the runtime returns (which, as a well known fact, sometimes does not represent the actual number of processors).
Every thread represents an internal event loop where all needed sockets are multiplexed on.
The default value should be fine most of the time, it may only need to be tuned if you run a very large number of nodes in the cluster or the runtime value is incorrect.
As a rule of thumb, it should roughly correlate with the number of cores available to the JVM.

Name: *Computation Thread Pool Size*::
Builder Method: `computationPoolSize(int)`
+
Default:  `2500ms`
+
System Property: `computationPoolSize`
| `Runtime# \available \Processors()`
| The number of threads in the computation thread pool.
This defaults to the number of available processors that the runtime returns (which, as a well known fact, sometimes does not represent the actual number of processors).
Every thread represents an internal event loop where all needed computation tasks are run.
The default value should be fine most of the time, it might only need to be tuned if you run more than usual CPU-intensive tasks and profiling the application indicates fully saturated threads in the pool.
As a rule of thumb, it should roughly correlate with the number of cores available to the JVM.

Name: *I/O Pool Group*::
Builder Method: `ioPool(EventLoopGroup)`
+
Default:  `NioEventLoopGroup`
+
System Property: `-`
+
For those who want the last drop of performance, on Linux Netty provides a way to use edge triggered epoll instead of going through JVM NIO.
This provides better throughput, lower latency and less garbage.
Note that this mode has not been tested by Couchbase and therefore is not supported officially.
If you like to take a walk on the wild side, you can find out more here: http://netty.io/wiki/native-transports.html[Netty Native-transports.^]

Name: *TCP Nodelay*::
Builder Method: `tcpNodelayEnabled(boolean)`
+
Default:  `true`
+
System Property: `tcpNodelayEnabled`
+
By default, TCP Nodelay is turned on (which in effect turns off "nagleing"), and if possible negotiated with the server as well.
If this is set to false, "nagleing" is turned on.
Make sure to only turn off TCP nodelay if you know what you are doing, because it can lead to decreased performance.

Name: *Run Callbacks on the I/O Pool*::
Builder Method: `callbacksOnIoPool(boolean)`
+
Default:  `false`
+
System Property: `callbacksOnIoPool`
+
If set to true, all callbacks will not be moved onto the scheduler but rather executed on the IO threads.
This can aid performance under high throughput scenarios but extra care must be taken to not block in a callback since this has direct impact on the performance of the I/O loops!



== Advanced Options

Values for the advanced options listed in the following table should not be changed unless there is a very good reason to do so.

Name: *Request Ring Buffer Size*::
Builder Method: `requestBufferSize(int)`
+
Default:  `16384`
+
System Property: `requestBufferSize`
+
The size of the request ring buffer where all request initially are stored and then picked up to be pushed onto the I/O threads.
Tuning this to a lower value will more quickly lead to BackpressureExceptions during overload or failure scenarios.
Setting it to a higher value means backpressure will take longer to occur, but more requests will potentially be queued up and more heap space is used.

Name: *Response Ring Buffer Size*::
Builder Method: `responseBufferSize(int)`
+
Default:  `16384`
+
System Property: `responseBufferSize`
+
The size of the response ring buffer where all responses are passed through from the I/O threads before the target Observable is completed.
Since the I/O threads are pushing data in this ring buffer, setting it to a lower value is likely to have a negative effect on I/O performance.
In general it should be kept in line with the request ring buffer size.

Name: *Computation Scheduler*::
Builder Method: `scheduler(Scheduler)`
+
Default:  `CoreScheduler`
+
System Property: `-`
+
The scheduler used for all CPU-intensive, non-blocking computations in the core, client and in user space.
This is a slightly modified version of the ComputationScheduler that ships with RxJava, mainly for the reason to manually name threads as needed.
Changing the scheduler should be used with extra care, especially since lots of internal components also depend on it.

Name: *User Agent String*::
Builder Method: `userAgent(String)`
+
Default:  `Based on OS, Runtime, and SDK Version`
+
System Property: `-`
+
The user agent string that is used to identify the SDK against the Couchbase Server cluster on different occasions, for example when doing a view or query request.
There is no need to tune that because it is dynamically generated based on properties set during build time (based on the package name and version, OS and runtime).

Name: *Package Name and Version Identifier*::
Builder Method: `packageNameAndVersion(String)`
+
Default:  `Based on SDK Version`
+
System Property: `-`
+
The package name and identifier is used as part of the user agent string and in the environment info output to see which version of the SDK the application is running.
There is no need to change it because it is dynamically generated based on properties set during build time.

Name: *Event Bus*::
Builder Method: `eventBus(EventBus)`
+
Default:  `DefaultEventBus`
+
System Property: `-`
+
The event bus implementation used to transport system, performance and debug events from producers to subscribers.
The default implementation is based on an internal RxJava Subject which does not cache the values and only pushes subsequent events to the subscribers.
If you provide a custom implementation, double check that it fits with the contract of the event bus as documented.

Name: *Buffer Pooling Enabled*::
Builder Method: `bufferPoolingEnabled(boolean)`
+
Default:  `true`
+
System Property: `bufferPoolingEnabled`
+
If the SDK is suspected to leak buffers (it pools buffers in its IO layer for performance) you can set this field to false.
This will make sure buffers are not pooled, but remember the tradeoff here is higher GC pressure on the system.
Only turn off to prevent a memory leak from happening (in production).
If you suspect a memory leak, please open a bug ticket.

Name: *Runtime Metrics Collector*::
Builder Method: `runtimeMetricsCollectorConfig(Metrics \CollectorConfig)`
+
Default:  `DefaultMetricsCollectorConfig`
+
System Property: `-`
+
The configuration of the runtime metrics collector can be modified (or completely disabled).
By default, it will emit an event every hour.

Name: *Network Latency Metrics Collector*::
Builder Method: `networkLatencyMetricsCollectorConfig(LatencyMetricsCollectorConfig)`
+
Default:  `DefaultLatencyMetricsCollectorConfig`
+
System Property: `-`
+
The configuration of the network latency metrics collector can be modified (or completely disabled).
By default, it will emit an event every hour, but collect the stats all the time.

Name: *Default Metrics Consumer*::
Builder Method: `defaultMetricsLoggingConsumer (boolean, CouchbaseLogLevel, OutputFormat)`
+
Default:  `enabled, INFO, JSON`
+
System Property: `-`
+
The default metric consumer which will log all metric events.
You can configure if it should be enabled, as well as the log level and the target output format.

Name: *Request Buffer Wait Strategy*::
Builder Method: `requestBufferWaitStrategy(WaitStrategy)`
+
Default:  `BlockingWaitStrategy`
+
System Property: `-`
+
The underlying request buffer can use a different wait strategy which can be used to get better performance under high throughput/low latency circumstances, trading CPU time for it.
This is an export option, only use it if you are comfortable with the LMAX Disruptor and know the impact of plugging in a different strategy!

Name: *Automatic Observable Resource Release Time Period*::
Builder Method: `autoreleaseAfter(int)`
+
Default:  `2000`
+
System Property: `-`
+
The time period in milliseconds that a subscriber needs to subscribe to the observable.
After this period, the resources involved in the observable are released and can't be subscribed to anymore.
This is required to avoid leaking data, it also needs to be a short time bound to avoid having the observable move into older GC generations unnecessarily, which harms performance.
