= Document basics
:page-topic-type: concept

[abstract]
Describes the properties and types of `Document` objects and how to use them.

== The Document

The `Document` class encapsulates the consolidated representation of all attributes that relate to a document stored on a Couchbase Server cluster.
It includes the document's identifier and related metadata.
A `Document` object contains the following properties:

|===
| Name | Description

| `id`
| The (per bucket) unique identifier of the document.

| `content`
| The actual content of the document.

| `cas`
| The CAS (Compare And Swap) value of the document.

| `expiry`
| The expiration time of the document.

| `mutationToken`
| The optional MutationToken after a mutation.
|===

There are a few different implementations of a `Document`, the most prominent one is the `JsonDocument`.

Because Couchbase Server can store anything and not just JSON, many document types exist to satisfy the general needs of an application.
You can also write your own `Document` implementations, which is not covered in this introduction.

NOTE: Every `Document` has an associated `Transcoder` that handles serialization and deserialization to and from the target wire format.
This conversion is transparent but needs to be taken into account when custom documents are implemented.

The following `Document` types are supported out of the box:

*Documents with JSON content:*

|===
| Document Name | Description | Compatible: 2.x SDKs | Compatible: 1.x Java SDK

| <<json,`JsonDocument`>>
| The default, which has a `JsonObject` at the top level content.
| Yes
| Yes

| <<jsonarray,`JsonArrayDocument`>>
| Similar to `JsonDocument`, but has a `JsonArray` at the top level content.
| Yes
| Yes

| <<jsonvalue,`JsonBooleanDocument`>>
| Stores JSON-compatible Boolean values.
| Yes
| Partially

| <<jsonvalue,`JsonLongDocument`>>
| Stores JSON compatible long (number) values.
| Yes
| Partially

| <<jsonvalue,`JsonDoubleDocument`>>
| Stores JSON compatible double (number) values.
| Yes
| Partially

| <<jsonvalue,`JsonStringDocument`>>
| Stores JSON compatible String values.
Input is automatically wrapped with `+"..."+`.
| Yes
| Partially

| <<jsonraw,`RawJsonDocument`>>
| Stores any JSON value and should be used if custom JSON serializers such as Jackson or GSON are already in use.
| Yes
| Yes

| `EntityDocument`
| Used with the Repository implementation to write and read POJOs into JSON and back.
| Yes
| Yes
|===

*Documents with other content:*

|===
| Document Name | Description | Compatible: 2.x SDKs | Compatible: 1.x Java SDK

| <<binary,`BinaryDocument`>>
| Can be used to store arbitrary binary data.
| Yes
| Yes

| <<serializable,`SerializableDocument`>>
| Stores objects that implement `Serializable` through default Java object serialization.
| No
| Yes

| <<legacy,`LegacyDocument`>>
| Uses the `Transcoder` from the 1.x SDKs and can be used for full cross-compatibility between the old and new versions.
| No
| Yes

| <<string,`StringDocument`>>
| Can be used to store arbitrary strings.
They will not be quoted, but stored as-is and flagged as "String".
| Yes
| Yes
|===

[caption="Backward compatibility"]
TIP: Other than the `LegacyDocument` class, which strives for full backward compatibility, all `Document` types are trying best effort in that regard.
Specific constraints are noted in each document description, but for all types keep in mind that compression is not supported other than on the `LegacyDocument`.

== CAS and Expiry

Every `Document` also contains the `expiry` and `cas` properties.
They are considered meta information and are optional.
An expiration time of `0` means that no expiration is set at all, and a `CAS` value 0 means it won't be used.

You can set the `expiry` to control when the document should be deleted:

[source,java]
----
// Expire in 10 seconds.
JsonDocument.create("id", 10, content);
----

[source,java]
----
// Expire in 1 day.
JsonDocument.create("id", TimeUnit.DAYS.toSeconds(1), content);
----

The expiration time starts when the document has been successfully stored on the server, not when the document was created on the application server.
Any expiration time larger than 30 days in seconds is considered absolute (as in a Unix time stamp), anything smaller is considered relative in seconds.

The `CAS` value can either be set by you directly or is populated by the SDK when the `Document` is loaded from the server (which is the recommended way to use it).

For detailed information about how to utilize CAS for optimistic concurrency control, see xref:documents-updating.adoc[Updating documents].

[#json]
== JsonDocument

Couchbase Server uses the JSON format as a first-class citizen.
It is used for querying (via both views and N1QL) and represents the main storage format that should be used.

The `JsonDocument` class has factory methods named `create()` that you use to create documents.
If you do not want to pass in an expiration time or CAS value (just the ID and content) you do it like this:

[source,java]
----
JsonDocument doc = JsonDocument.create("id", content);
----

The content needs to be of type `JsonObject`, which ships with the Java SDK.
It works very much like a `Map` object but makes sure only data types understood by JSON are used.

An empty JSON document can be created like this:

[source,java]
----
JsonObject content = JsonObject.empty();
----

After it is created, you can use the various `put()` methods to insert data:

[source,java]
----
JsonArray friends = JsonArray.empty()
	.add(JsonObject.empty().put("name", "Mike Ehrmantraut"))
	.add(JsonObject.empty().put("name", "Jesse Pinkman"));

JsonObject content = JsonObject.empty()
	.put("firstname", "Walter")
	.put("lastname", "White")
	.put("age", 52)
	.put("aliases", JsonArray.from("Walt Jackson", "Mr. Mayhew", "David Lynn"))
	.put("friends", friends);
----

This generates a JSON document like this (unordered, because the actual content is stored in a `Map`):

[source,json]
----
{
   "firstname":"Walter",
   "aliases":[
	  "Walt Jackson",
	  "Mr. Mayhew",
	  "David Lynn"
   ],
   "age":52,
   "friends":[
	  {
		 "name":"Mike Ehrmantraut"
	  },
	  {
		 "name":"Jesse Pinkman"
	  }
   ],
   "lastname":"White"
}
----

[#image_i31_yqb_1]
image::document-jsonobject.png[,650px]

In addition, the `JsonObject` and `JsonArray` classes provide convenience methods to generate and modify them.

The `JsonDocument` can then be passed into the various operations on the `Bucket`:

[source,java]
----
JsonDocument walter = JsonDocument.create("user:walter", content);
JsonDocument inserted = bucket.insert(walter);
----

If you want to read values out of the `JsonDocument`, you can use either the typed or untyped getter methods.

[source,java]
----
int age = content.getInt("age");
String name = content.getString("firstname") + content.getString("lastname");
----

NOTE: If you are accessing values that potentially do not exist, you need to use boxed values (`Integer`, `Long`, `Boolean`) instead of their unboxed variants (`int`, `long`, `boolean`) to avoid getting `NullPointerException` exceptions.
If you use unboxed variants, make sure to catch them properly.

[#jsonarray]
== JsonArrayDocument

The `JsonArrayDocument` class works exactly like the `JsonDocument` class, with the main difference that you can have a JSON array at the top level content (instead of an object).

So if you create a `JsonArrayDocument` like this:

[source,java]
----
JsonArray content = JsonArray.from("Hello", "World", 1234);
bucket.upsert(JsonArrayDocument.create("docWithArray", content));
----

It will look like this on the server:

[#image_json-array]
image::document-jsonarray.png[,650px]

If you want to read the `JsonArrayDocument` back, you need to tell the SDK that you explicitly want to deviate from the default.
Do it for every document type other than `JsonDocument`:

[source,java]
----
bucket.get("docWithArray", JsonArrayDocument.class);
----

[#jsonraw]
== RawJsonDocument

The `JsonObject` and `JsonArray` types have been added for developer convenience.
In a lot of places, custom JSON handling is already in place through libraries like Jackson or Google GSON.

Of course, we want to provide the best of both worlds, and this is where the `RawJsonDocument` comes into play.
You can store and read the already stringified JSON, but the SDK properly marks it as JSON, so it is cross-compatible with all other documents.

Here is how you can read and write raw JSON data.
For clarity, a plain string is used but it is up to you to wire this up with Jackson or a similar JSON processor:

[source,java]
----
// write the raw data
String content = "{\"hello\": \"couchbase\", \"active\": true}";
bucket.upsert(RawJsonDocument.create("rawJsonDoc", content));

// read the raw data
// prints RawJsonDocument{id='rawJsonDoc', cas=..., expiry=0, content={"hello": "couchbase", "active": true}}
System.out.println(bucket.get("rawJsonDoc", RawJsonDocument.class));

// read it parsed
// prints true
System.out.println(bucket.get("rawJsonDoc").content().getBoolean("active"));
----

image::document-rawjson.png[,650px]

NOTE: If you use the `RawJsonDocument` type, the SDK does not perform any validation because the expectation is that a JSON-compatible library is used, and additional overhead will be avoided.

[#jsonvalue]
== JSON value documents

The JSON specification also allows you to store different values as content, and it also specifies how these values need to be encoded.
Because the type system of Java is not as rich as it could be, different document types are provided to represent different values that can be stored.
Because the encoding is clearly defined, these JSON values are also compatible with other 2.0 SDKs.

A word on compatibility with the 1.X Java SDK: in a best-effort way the SDK tries to read properly flagged data from the old SDKs, but it stores it under the new format, which is not readable by the old SDKs anymore.
So if you care about back-and-forth compatibility only read those values from the new SDK or use the `LegacyDocument` right away.
Another option is to use strings only on the old SDK, and then working with it back and forth should be safe.

Backward compatibility for JSON value documents works only if the actual content is not compressed.

The following documents exist, which all work similarly except the content type that can be stored:

* `JsonBooleanDocument`
* `JsonLongDocument`
* `JsonDoubleDocument`
* `JsonStringDocument`

They are all encoded and decoded based on their http://json.org[JSON specification^].

[#binary]
== BinaryDocument

The `BinaryDocument` can be used to store and read arbitrary bytes.
It is the only default codec that directly exposes the underlying low-level Netty `ByteBuf` objects.

IMPORTANT: Because the raw data is exposed, it is important to free it after it has been properly used.
Not freeing it will result in increased garbage collection and memory leaks and should be avoided by all means.
See <<binary-memory>>.

Because binary data is arbitrary anyway, it is backward compatible with the old SDK regarding flags so that it can be read and written back and forth.
Make sure it is not compressed in the old SDK and that the same encoding and decoding process is used on the application side to avoid data corruption.

Here is some demo code that shows how to write and read raw data.
The example writes binary data, reads it back, and then frees the pooled resources:

[source,java]
----
// Create buffer out of a string
ByteBuf toWrite = Unpooled.copiedBuffer("Hello World", CharsetUtil.UTF_8);

// Write it
bucket.upsert(BinaryDocument.create("binaryDoc", toWrite));

// Read it back
BinaryDocument read = bucket.get("binaryDoc", BinaryDocument.class);

// Print it
System.out.println(read.content().toString(CharsetUtil.UTF_8));

// Free the resources
ReferenceCountUtil.release(read.content());
----

[#binary-memory]
== Correctly managing buffers

`BinaryDocument` allows users to get the rawest form of data out of Couchbase.
It  exposes Netty's `ByteBuf`, byte buffers that can have various characteristics (on- or off-heap, pooled or unpooled).
In general, buffers created by the SDK are pooled and off heap.
You can disable the pooling in the `CouchbaseEnvironment` if you absolutely need that.

As a consequence, the memory associated with the ByteBuf must be a little bit more managed by the developer than usual in Java.

Most notably, these byte buffers are reference counted, and you need to know three main methods associated to buffer management:

* `refCnt()` gives you the current reference count.
When it hits 0, the buffer is released back to its original pool, and it cannot be used anymore.
* `release()` will decrease the reference count by 1 (by default).
* `retain()` is the inverse of release, allowing you to prepare for multiple consumptions by external methods that you know will each release the buffer.

You can also use `ReferenceCountUtil.release(something)` if you don't want to check if `something` is actually a `ByteBuf` (will do nothing if it's not something that is [.api]`ReferenceCounted`).

IMPORTANT: The SDK bundles the Netty dependency into a different package so that it doesn't clash with a dependency to another version of Netty you may have.
As such, you need to use the classes and packages provided by the SDK (`com.couchbase.client.deps.io.netty`) when interacting with the API.
For example, the `ByteBuf` for the content of a `BinaryDocument` is a `com.couchbase.client.deps.io.netty.buffer.ByteBuf`.

*What happens if I don't release?*

Basically, you leak memory\...

Netty will by default inspect a small percentage of `ByteBuf` creations and usage to try and detect leaks (in which case it will output a log, look for the "LEAK" keyword).

You can tune that to be more eagerly monitoring all buffers by calling `ResourceLeakDetector.setLevel(PARANOID)`.

IMPORTANT: Note that this incurs quite an overhead and should only be activated in tests.
In production (prod), setting it to `ADVANCED` is not as heavy as paranoid and can be a good middle ground.

*What happens if I release twice (or the SDK releases once more after I do)?*

Netty will throw an `IllegalReferenceCountException`.
The buffer that has RefCnt = 0 cannot be interacted with anymore since it means it has been freed back into the pool.

*When must I release?*

When the SDK creates a `BinaryDocument` for you, basically GET-type operations.

Mutative operations, on the other hand, will take care of the buffer you pass in for you, at the time the buffer is written on the wire.

*When must I usually retain?*

When you do a write, the buffer will usually be released by the SDK calling `release()`.
But if you implement a kind of fallback behavior (for instance attempt to `insert()` a doc, catch `DocumentAlreadyExistException` and then fallback to an `update()` instead), that means the SDK would attempt to release twice, which won't work.

In this case you can `retain()` the buffer before the first attempt, let the catch block do the extra release if something goes wrong.
You have to manage the extra release if the first write succeeds, and think about catching other possible exceptions (here also an extra release is needed):

[source,java]
----
byteBuffer.retain(); //prepare for potential multi usage (+1 refCnt, refCnt = 2)
try {
   bucket.append(document);
   // refCnt = 2 on success
   byteBuffer.release(); //refCnt = 1
} catch (DocumentDoesNotExistException dneException) {
   // buffer is released on errors, refCnt = 1
   //second usage will also release, but we want to be at refCnt = 1 for the finally block
   byteBuffer.retain(); //refCnt = 2
   bucket.insert(document); //refCnt = 1
} // other uncaught errors will still cause refCnt to be released down to 1
finally {
   //we made sure that at this point refCnt = 1 in any case (success, caught exception, uncaught exception)
   byteBuffer.release(); //refCnt = 0, returned to the pool
}
----

== SerializableDocument

Any object that implements `Serializable` can be safely encoded and decoded using the built-in Java serialization mechanism.
While it is very convenient, it can be slow in cases where the POJOs are very complex and deeply nested.
It is backward compatible with the old SDK unless the data has been compressed previously.

Here is an example that serializes a POJO, deserializes it later, and then prints one of its properties:

[source,java]
----
import java.io.Serializable;

public class User implements Serializable {

	private final String username;

	public User(String username) {
		this.username = username;
	}

	public String getUsername() {
		return username;
	}

}
----

[source,java]
----
// Create the User and store it
bucket.upsert(SerializableDocument.create("user::michael",  new User("Michael")));

// Read it back
SerializableDocument found = bucket.get("user::michael", SerializableDocument.class);

// Print a property to verify
System.out.println(((User) found.content()).getUsername());
----

[#legacy]
== LegacyDocument

The `LegacyDocument` is intended to be 1:1 compatible (including compression) with the 1.x Java SDK.
For better compatibility with the other 2.0 SDKs, we recommend to move to JSON type documents (and other compatible ones), but the `LegacyDocument` is very helpful during data migration and side-by-side usage.

Because the old and new SDKs don't share artifacts or namespaces, they can be used at the same time.
If you're using Maven, you can add both a 1.x SDK and a 2.x SDK as dependencies in the [.path]_pom.xml_ file.
For example:

[source,xml]
----
<dependencies>
	<dependency>
		<groupId>com.couchbase.client</groupId>
		<artifactId>java-client</artifactId>
		<version>2.2.8</version>
	</dependency>
	<dependency>
		<groupId>com.couchbase.client</groupId>
		<artifactId>couchbase-client</artifactId>
		<version>1.4.11</version>
	</dependency>
</dependencies>
----

Here is a snippet that writes a value using the old SDK and reads it out with the new one:

[source,java]
----
// Open bucket on the new SDK
Cluster cluster = CouchbaseCluster.create();
Bucket bucket = cluster.openBucket();

// Open bucket on the old SDK
CouchbaseClient client = new CouchbaseClient(
	Arrays.asList(URI.create("http://127.0.0.1:8091/pools")),
	"default",
	""
);

// Create document on old SDK
client.set("fromOld", "Hello from Old!").get();

// Create document on new SDK
bucket.upsert(LegacyDocument.create("fromNew", "Hello from New!"));

// Read old from new
System.out.println(bucket.get("fromOld", LegacyDocument.class));

// Read new from old
System.out.println(client.get("fromNew"));

// Shutdown old client
client.shutdown();

// Shutdown new client
cluster.disconnect();
----

This prints:

----
LegacyDocument{id='fromOld', cas=1097880624822, expiry=0, content=Hello from Old!}
Hello from New!
----

[#string]
== StringDocument

This document type provides an SDK 2.0 cross-compatible way to exchange strings.
It should not be mistaken with the `JsonStringDocument` that automatically quotes it and also flags it as JSON.
It is also backward compatible unless compression was used previously.

If a `String` is stored through it, it is explicitly flagged as a non-JSON string.
The usage is straightforward:

[source,java]
----
// Create the document
bucket.upsert(StringDocument.create("stringDoc", "Hello World"));

// Prints:
// StringDocument{id='stringDoc', cas=1424054670330, expiry=0, content=Hello World}
System.out.println(bucket.get("stringDoc", StringDocument.class));
----

You can use the `cbc` command line tool to compare the flags and actual content compared to the `JsonStringDocument`:

[source,java]
----
bucket.upsert(StringDocument.create("stringDoc", "Hello World"));
----

[source,bash]
----
└──╼ cbc cat stringDoc
stringDoc            CAS=0x55668b55f010000, Flags=0x4000000. Size=11
Hello World
----

[source,java]
----
bucket.upsert(JsonStringDocument.create("jsonStringDoc", "Hello World"));
----

[source,bash]
----
└──╼ cbc cat jsonStringDoc
jsonStringDoc        CAS=0x84d77eb55f010000, Flags=0x2000000. Size=13
"Hello World"
----

You can see that the JSON string got automatically quoted and also has different flags applied to it.
